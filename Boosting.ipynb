{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Decision Stumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The banknotes dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "import pandas as pd\n",
    "\n",
    "banknotes = pd.read_csv('banknotes-data.csv', sep=',', header=0).sample(frac=1)\n",
    "\n",
    "banknotes_x = banknotes.values[:, :-1]\n",
    "banknotes_y = banknotes.values[:, -1]\n",
    "\n",
    "# split the data into the training and test dataset\n",
    "test_X = banknotes_x[:500]\n",
    "test_y = banknotes_y[:500]\n",
    "train_X = banknotes_x[500:]\n",
    "train_y = banknotes_y[500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best decision stump for each coordinate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDecisionStump(train_X, train_y):\n",
    "    #variables\n",
    "    features = train_X.shape[1]\n",
    "    threshold = [0 for _ in range(features)]\n",
    "    error = [float('inf') for _ in range(features)]\n",
    "    stump_type = ['minus' for _ in range(features)]  \n",
    "\n",
    "    #finding best threshold for each feature\n",
    "    for i in range(features):\n",
    "        #get unique values for each feature\n",
    "        feature = train_X[:, i]\n",
    "        threshold_values = pd.unique(feature)\n",
    "\n",
    "        #itterating over unique feature values to find best threshold for each feature\n",
    "        for value in threshold_values:\n",
    "            err_minus = err_plus = 0\n",
    "            for j in range(len(train_y)):\n",
    "                if feature[j] < value:\n",
    "                    err_minus += (train_y[j] != 1)\n",
    "                else:\n",
    "                    err_minus += (train_y[j] != 0)\n",
    "\n",
    "                if feature[j] >= value:\n",
    "                    err_plus += (train_y[j] != 1)\n",
    "                else:\n",
    "                    err_plus += (train_y[j] != 0)\n",
    "\n",
    "            err_minus /= len(train_y)\n",
    "            err_plus /= len(train_y)\n",
    "\n",
    "            if err_minus < error[i]:\n",
    "                threshold[i] = value\n",
    "                error[i] = err_minus\n",
    "                stump_type[i] = 'minus'\n",
    "\n",
    "            if err_plus < error[i]:\n",
    "                threshold[i] = value\n",
    "                error[i] = err_plus\n",
    "                stump_type[i] = 'plus'\n",
    "\n",
    "    return threshold, error, stump_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: optimal\n",
      "optimal value 29819.999988680618\n",
      "optimal var 71.99999982368749 84.00000005686965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/cvxpy/reductions/solvers/solving_chain.py:336: FutureWarning: \n",
      "    Your problem is being solved with the ECOS solver by default. Starting in \n",
      "    CVXPY 1.5.0, Clarabel will be used as the default solver instead. To continue \n",
      "    using ECOS, specify the ECOS solver explicitly using the ``solver=cp.ECOS`` \n",
      "    argument to the ``problem.solve`` method.\n",
      "    \n",
      "  warnings.warn(ECOS_DEPRECATION_MSG, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "\n",
    "# Create two scalar optimization variables\n",
    "x = cvx.Variable()\n",
    "y = cvx.Variable()\n",
    "\n",
    "# Create constraints\n",
    "constraints = [x >= 0,\n",
    "               y >= 0,\n",
    "               x + y <= 180,\n",
    "               x + 2*y <= 240,\n",
    "               3 * x + y <= 300]\n",
    "\n",
    "# Form objective\n",
    "obj = cvx.Maximize(140*x +235*y)\n",
    "\n",
    "# Form and solve problem.\n",
    "prob = cvx.Problem(obj, constraints)\n",
    "prob.solve()  \n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)\n",
    "print(\"optimal var\", x.value, y.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVXPY also allows for multi-dimensional variables and point-wise constraints, and combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: optimal\n",
      "optimal value 1.71428571412859\n",
      "optimal var [0.57142857 0.57142857]\n"
     ]
    }
   ],
   "source": [
    "x = cvx.Variable(2, nonneg=True)\n",
    "A = np.array(((1, 2), (3, 4)))\n",
    "y = cvx.Variable()\n",
    "c = np.ones(2)\n",
    "\n",
    "constrains = [A @ x <= 4,\n",
    "              x >= y]\n",
    "\n",
    "obj = cvx.Maximize(c @ x + y)\n",
    "\n",
    "prob = cvx.Problem(obj, constrains)\n",
    "prob.solve()\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)\n",
    "print(\"optimal var\", x.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Weak Learner Training Error: [0.15958668197474168, 0.29965556831228474, 0.37083811710677383, 0.4397244546498278]\n",
      "Status: optimal\n",
      "Optimal LP Values [0.32839585 0.34782904 0.05824235 0.26553275] -5.012127671565756e-12\n",
      "Empirical Error of the Boosted Classifier on the Test Data: 0.098\n",
      "Empirical Errors for Each Feature Weak Learner: [0.124, 0.29, 0.378, 0.434]\n",
      "We can see that the aggregated classifier has a lower error than any of the weak learners. The worst weak learner has an error of .124 and the aggregated classifier has an error of .098.\n"
     ]
    }
   ],
   "source": [
    "threshold, trainingerror, stump_types = findDecisionStump(train_X, train_y)\n",
    "\n",
    "print(\"Empirical Weak Learner Training Error:\", trainingerror)\n",
    "\n",
    "#matrix A\n",
    "A = np.zeros((len(train_y), 4))\n",
    "\n",
    "#filling A\n",
    "for i in range(len(train_y)):\n",
    "    for j in range(4):\n",
    "        #best stump is s^-_{j,t}\n",
    "        if stump_types[j] == 'minus':\n",
    "            #marking 1 for misclassification\n",
    "            A[i][j] = 1 if (train_X[i][j] < threshold[j] and train_y[i] != 1) or (train_X[i][j] >= threshold[j] and train_y[i] == 1) else 0\n",
    "        #best stump is s^+_{j,t}\n",
    "        elif stump_types[j] == 'plus':\n",
    "            #marking 1 for misclassification\n",
    "            A[i][j] = 1 if (train_X[i][j] >= threshold[j] and train_y[i] != 1) or (train_X[i][j] < threshold[j] and train_y[i] == 1) else 0\n",
    "\n",
    "\n",
    "#variables to max over\n",
    "p = cvx.Variable(4) #dsitribution over the 4 features\n",
    "t = cvx.Variable()   \n",
    "\n",
    "constraints = [cvx.sum(p) == 1,  #p must sum to 1\n",
    "               p >= 0,           #p must be non-negative\n",
    "               A @ p >= t        #for each i, (Ap)_i >= t\n",
    "              ]\n",
    "\n",
    "\n",
    "objective = cvx.Maximize(t)\n",
    "#defining and solving the problem\n",
    "problem = cvx.Problem(objective, constraints)\n",
    "problem.solve(solver=cvx.ECOS)\n",
    "\n",
    "#empirical prediction error for aggregated classifier\n",
    "empirical_error = 0\n",
    "\n",
    "#classifiction of each feature weak learner for each data point on the test data\n",
    "A = np.zeros((len(test_y), 4))\n",
    "for i in range(len(test_y)):\n",
    "    for j in range(4):\n",
    "        #best stump is s^-_{j,t}, \n",
    "        if stump_types[j] == 'minus':\n",
    "            #marking 1 for classification\n",
    "            A[i][j] = 1 if test_X[i][j] < threshold[j] else 0\n",
    "        #best stump is s^+_{j,t}    \n",
    "        elif stump_types[j] == 'plus':\n",
    "            #marking 1 for classification\n",
    "            A[i][j] = 1 if test_X[i][j] >= threshold[j] else 0\n",
    "\n",
    "#empirical prediction error for aggregated classifier\n",
    "for i in range(len(test_y)):\n",
    "    prediction_error = np.dot(A[i], p.value)\n",
    "    if (prediction_error < .5 and test_y[i] == 1) or (prediction_error >= .5 and test_y[i] == 0):\n",
    "        empirical_error += 1\n",
    "empirical_error /= len(test_y)\n",
    "\n",
    "#calculate learner errors for test data\n",
    "error = [0, 0, 0, 0]\n",
    "for i in range(4):\n",
    "    for j in range(len(test_y)):\n",
    "        #best stump is s^-_{j,t}\n",
    "        if stump_types[i] == 'minus':\n",
    "            #adding 1 to error if misclassified\n",
    "            error[i] += 1 if (test_X[j][i] < threshold[i] and test_y[j] != 1) or (test_X[j][i] >= threshold[i] and test_y[j] == 1) else 0\n",
    "        #best stump is s^+_{j,t}\n",
    "        elif stump_types[i] == 'plus':\n",
    "            #adding 1 to error if misclassified\n",
    "            error[i] += 1 if (test_X[j][i] >= threshold[i] and test_y[j] != 1) or (test_X[j][i] < threshold[i] and test_y[j] == 1) else 0\n",
    "\n",
    "    error[i] /= len(test_y)\n",
    "print(\"Status:\", problem.status)\n",
    "print(\"Optimal LP Values\", p.value, t.value)\n",
    "print(\"Empirical Error of the Boosted Classifier on the Test Data:\", empirical_error)\n",
    "print(\"Empirical Errors for Each Feature Weak Learner:\", error)\n",
    "print(\"We can see that the aggregated classifier has a lower error than any of the weak learners. The worst weak learner has an error of .124 and the aggregated classifier has an error of .098.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
